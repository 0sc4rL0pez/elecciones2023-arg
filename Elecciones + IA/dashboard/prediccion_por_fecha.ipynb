{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\54911\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import load_model\n",
    "import joblib\n",
    "from keras.metrics import RootMeanSquaredError,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pasar_a_datetime(fecha):\n",
    "    #format_string = '%Y-%m-%d'\n",
    "    anio,mes,dia= fecha.split('-')\n",
    "    aux_dia = dia.split(' ')\n",
    "    if len(aux_dia)>1:dia = aux_dia[0]\n",
    "    res = datetime(int(anio),int(mes),int(dia))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_datasets(x_train, x_test):\n",
    "\n",
    "  \"\"\"\n",
    "  Standard Scale test and train data\n",
    "  Z - Score normalization\n",
    "  \"\"\"\n",
    "  standard_scaler = StandardScaler()\n",
    "  x_train_scaled = pd.DataFrame(\n",
    "      standard_scaler.fit_transform(x_train),\n",
    "      columns=x_train.columns\n",
    "  )\n",
    "  x_test_scaled = pd.DataFrame(\n",
    "      standard_scaler.transform(x_test),\n",
    "      columns = x_test.columns\n",
    "  )\n",
    "  return x_train_scaled, x_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "\n",
    "Dada un intervalo de fecha retornar la prediccion del modelo\n",
    "\n",
    "Esos intervalos pueden ser aquellos establecidos en encuestas (agrupados mean())\n",
    "\n",
    "Guardar ambas tablas, calcular score para cada fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "publicaciones = pd.read_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/Preparando_datos/publicaciones_politicas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_fechas(datos_publicaciones, inicio, final):\n",
    "    aux_datos_publicaciones = datos_publicaciones['fecha'].map(lambda x:pasar_a_datetime(x))\n",
    "    res = datos_publicaciones[(aux_datos_publicaciones>=inicio) & (aux_datos_publicaciones<=final)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_fecha(data):\n",
    "    data['dia'] = ''\n",
    "    data['mes'] = ''\n",
    "    data['anio'] = ''\n",
    "    data['dia'] = data['fecha_mediana'].map(lambda x:x.day)\n",
    "    data['mes'] = data['fecha_mediana'].map(lambda x:x.month)\n",
    "    data['anio'] = data['fecha_mediana'].map(lambda x:x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_Fuente(tabla,fuentes):\n",
    "    #fuentes_labels = publicaciones['fuente'].unique()\n",
    "    numbers = [i+1 for i in range(len(fuentes))]\n",
    "    simple_encoding = dict(zip(fuentes,numbers))\n",
    "    tabla['Fuente'] = tabla['Fuente'].map(lambda x:simple_encoding[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formato_entrenado(datos_publicaciones_input,partidos):\n",
    "    datos_publicaciones = datos_publicaciones_input.copy()\n",
    "    datos_publicaciones['fecha']=datos_publicaciones['fecha'].map(lambda x:pasar_a_datetime(x))\n",
    "    fuentes = datos_publicaciones['fuente'].unique()\n",
    "    #partidos = ['La Libertad Avanza','Union por la Patria']\n",
    "    #partidos = publicaciones['Partido'].unique() \n",
    "    #datos_publicaciones['fecha'] = datos_publicaciones['fecha'].map(lambda x:pasar_a_datetime(x))\n",
    "\n",
    "    #datos_publicaciones['cantidad_likes'].quantile(0.95)\n",
    "    datos_publicaciones = datos_publicaciones[datos_publicaciones['cantidad_likes']<25000]\n",
    "\n",
    "    \n",
    "    agrupado_likes = datos_publicaciones.groupby(['Partido','fuente'])['cantidad_likes'].median()\n",
    "    fecha_median = datos_publicaciones['fecha'].median()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for p in list(partidos):\n",
    "\n",
    "        if p in agrupado_likes.index:\n",
    "            likes_partidos = agrupado_likes[p]\n",
    "            fuentes_partido = likes_partidos.index\n",
    "            likes_median = []\n",
    "\n",
    "            for c in fuentes:\n",
    "                if c in fuentes_partido:\n",
    "                    likes_median.append(likes_partidos[c])\n",
    "                else:\n",
    "                    likes_median.append(0)\n",
    "        \n",
    "            df[p] = likes_median\n",
    "        else:\n",
    "            df[p] = [0]*len(fuentes)\n",
    "\n",
    "\n",
    "    df['Fuente'] = fuentes\n",
    "    df['fecha_mediana'] = fecha_median\n",
    "\n",
    "    \n",
    "    separar_fecha(df)\n",
    "    df.drop(['fecha_mediana','anio'],axis=1,inplace=True)\n",
    "    encoding_Fuente(df,fuentes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acomodar_prediccion(prediccion,partidos):\n",
    "\n",
    "    resultados_mean = []\n",
    "    for i in range(len(partidos)):\n",
    "        resultados_mean.append(prediccion[:,i].mean())\n",
    "\n",
    "    total = sum(resultados_mean)\n",
    "    resultados_norm = []\n",
    "    for r in resultados_mean:\n",
    "        aux = 100*r/total\n",
    "        resultados_norm.append(aux)\n",
    "\n",
    "    resultados_norm = [round(x,1) for x in resultados_norm]\n",
    "\n",
    "    df = pd.DataFrame({'Partido':partidos,'Resultado':resultados_norm})\n",
    "\n",
    "    return df,resultados_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion_dada_fecha(model,scaler,inicio,final,partidos):\n",
    "    # inicio = datetime(2023,4,1)\n",
    "    # final = datetime(2023,4,14)\n",
    "    periodo_fecha = filtrar_fechas(publicaciones,inicio,final)\n",
    "    periodo_fecha_formato = formato_entrenado(periodo_fecha,partidos)\n",
    "\n",
    "    if len(partidos)==5:\n",
    "        periodo_fecha_formato = periodo_fecha_formato.iloc[:,[1,2,0,4,3,5,6,7]]\n",
    "\n",
    "    periodo_fecha_formato_scaled = scaler.transform(periodo_fecha_formato)\n",
    "    prediccion_fecha = model.predict(periodo_fecha_formato_scaled,verbose=0)\n",
    "    #partidos = periodo_fecha_formato.columns[:2]\n",
    "    df,resultados_norm= acomodar_prediccion(prediccion_fecha,partidos)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\54911\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\54911\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:585: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = joblib.load('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/scaler_primeravuelta.gz')\n",
    "model_primera_vuelta = load_model('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/modelo_primera_vuelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encuestas_primera_vuelta = pd.read_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/getting_data/encuestas/Encuestas_primera_vuelta.csv')\n",
    "Encuestas_agrupado_prim = Encuestas_primera_vuelta.groupby(['Inicio','Final']).mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "partidos = publicaciones['Partido'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "predicciones = np.zeros((5,len(Encuestas_agrupado_prim)))\n",
    "for i in range(len(Encuestas_agrupado_prim)):\n",
    "    \n",
    "    fila = Encuestas_agrupado_prim.iloc[i]\n",
    "    inicio = fila['Inicio']\n",
    "    final = fila['Final']\n",
    "    predicho = prediccion_dada_fecha(model_primera_vuelta,scaler,pasar_a_datetime(inicio),pasar_a_datetime(final),partidos)\n",
    "    valores_pred = predicho['Resultado'].to_numpy(dtype=float)\n",
    "    esperado = np.array(fila.values[2:],dtype=float)\n",
    "\n",
    "    score.append(-mean_squared_error(esperado,valores_pred).numpy())\n",
    "\n",
    "    for k,p in enumerate(partidos):\n",
    "        # lista_partido = predicciones[p]\n",
    "        # lista_partido.append(valores_pred[k])\n",
    "        predicciones[k,i] =  valores_pred[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_score_df = pd.DataFrame()\n",
    "predicciones_score_df['Scores'] = score\n",
    "for i in range(5):\n",
    "    predicciones_score_df[partidos[i]] = predicciones[i]\n",
    "\n",
    "predicciones_score_df['Inicio'] = Encuestas_agrupado_prim['Inicio']\n",
    "predicciones_score_df['Final'] = Encuestas_agrupado_prim['Final']\n",
    "predicciones_score_df['Inicio']= predicciones_score_df['Inicio'].map(lambda x:pasar_a_datetime(x))\n",
    "predicciones_score_df['Final']= predicciones_score_df['Final'].map(lambda x:pasar_a_datetime(x))\n",
    "\n",
    "predicciones_score_df = predicciones_score_df[predicciones_score_df['Inicio']>datetime(2022,12,31)]\n",
    "predicciones_score_df = predicciones_score_df[predicciones_score_df['Final']>datetime(2022,12,31)]\n",
    "predicciones_score_df.rename(columns=dict(zip(predicciones_score_df.columns,predicciones_score_df.columns[[0,1,3,2,4,5,6,7]])),inplace=True)\n",
    "predicciones_score_df.to_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/dashboard/predicciones_score_df_prim.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ballotaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/scaler_ballotaje.gz')\n",
    "model= load_model('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/modelo_ballotaje')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encuestas = pd.read_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/getting_data/encuestas/Encuestas_solo_ballotaje.csv')\n",
    "Encuestas_agrupado_ = Encuestas.groupby(['Inicio','Final']).mean().reset_index()\n",
    "\n",
    "partidos = Encuestas_agrupado_.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "predicciones = np.zeros((2,len(Encuestas_agrupado_)))\n",
    "for i in range(len(Encuestas_agrupado_)):\n",
    "    \n",
    "    fila = Encuestas_agrupado_.iloc[i]\n",
    "    inicio = fila['Inicio']\n",
    "    final = fila['Final']\n",
    "    predicho = prediccion_dada_fecha(model,scaler,pasar_a_datetime(inicio),pasar_a_datetime(final),partidos)\n",
    "    valores_pred = predicho['Resultado'].to_numpy(dtype=float)\n",
    "    esperado = np.array(fila.values[2:],dtype=float)\n",
    "\n",
    "    score.append(-mean_squared_error(esperado,valores_pred).numpy())\n",
    "\n",
    "    for k,p in enumerate(partidos):\n",
    "        # lista_partido = predicciones[p]\n",
    "        # lista_partido.append(valores_pred[k])\n",
    "        predicciones[k,i] =  valores_pred[k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_score_df = pd.DataFrame()\n",
    "predicciones_score_df['Scores'] = score\n",
    "for i in range(2):\n",
    "    predicciones_score_df[partidos[i]] = predicciones[i]\n",
    "\n",
    "predicciones_score_df['Inicio'] = Encuestas_agrupado_['Inicio']\n",
    "predicciones_score_df['Final'] = Encuestas_agrupado_['Final']\n",
    "predicciones_score_df['Inicio']= predicciones_score_df['Inicio'].map(lambda x:pasar_a_datetime(x))\n",
    "predicciones_score_df['Final']= predicciones_score_df['Final'].map(lambda x:pasar_a_datetime(x))\n",
    "\n",
    "predicciones_score_df = predicciones_score_df[predicciones_score_df['Inicio']>datetime(2022,12,31)]\n",
    "predicciones_score_df = predicciones_score_df[predicciones_score_df['Final']>datetime(2022,12,31)]\n",
    "\n",
    "#predicciones_score_df.to_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/dashboard/predicciones_score_ballotaje.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
