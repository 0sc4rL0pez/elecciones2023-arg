{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\54911\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN,LSTM\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler \n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import MeanSquaredLogarithmicError,MeanSquaredError,MeanAbsolutePercentageError,Huber\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pasar_a_datetime(fecha):\n",
    "    #format_string = '%Y-%m-%d'\n",
    "    anio,mes,dia= fecha.split('-')\n",
    "    aux_dia = dia.split(' ')\n",
    "    if len(aux_dia)>1:dia = aux_dia[0]\n",
    "    res = datetime(int(anio),int(mes),int(dia))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_datasets(x_train, x_test):\n",
    "    #min_max = MinMaxScaler ()\n",
    "    stdscaler = StandardScaler()\n",
    "    x_train_scaled = pd.DataFrame(\n",
    "        stdscaler.fit_transform(x_train),\n",
    "        columns=x_train.columns\n",
    "    )\n",
    "    x_test_scaled = pd.DataFrame(\n",
    "        stdscaler.transform(x_test),\n",
    "        columns = x_test.columns\n",
    "    )\n",
    "    return x_train_scaled, x_test_scaled,stdscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordenar_fecha(data):\n",
    "    data['fecha_mediana'] = data['fecha_mediana'].map(lambda x: pasar_a_datetime(x))\n",
    "    data.sort_values(by='fecha_mediana',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos_entrenamiento(X_train, X_test):\n",
    "    x_train_scaled, x_test_scaled,stdscaler = scale_datasets(X_train, X_test)\n",
    "    return x_train_scaled, x_test_scaled,stdscaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliteo_data(datos, split_training):\n",
    "    cols = datos.columns.to_list()\n",
    "    idx = cols.index('Fuente')\n",
    "    x_cols = cols[:idx+1]+cols[-2:]\n",
    "    y_cols = cols[idx+2:-2]\n",
    "\n",
    "    x = datos.loc[:,x_cols]\n",
    "    y = datos.loc[:,y_cols]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=split_training,shuffle=True,random_state=2023)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test,x_cols,y_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_primera_vuelta = pd.read_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/data_primera_vuelta.csv')\n",
    "data_ballotaje = pd.read_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/data_ballotaje.csv')\n",
    "data_median = pd.read_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/data_median.csv')\n",
    "data_solo_ballotaje = pd.read_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/data_solo_ballotaje.csv')\n",
    "data_encuestas_poly = pd.read_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/data_encuestas_poly.csv')\n",
    "data_ballotaje_poly = pd.read_csv('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/data_ballotaje_poly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordenar_fecha(data_primera_vuelta)\n",
    "ordenar_fecha(data_ballotaje)\n",
    "ordenar_fecha(data_median)\n",
    "ordenar_fecha(data_solo_ballotaje)\n",
    "ordenar_fecha(data_encuestas_poly)\n",
    "ordenar_fecha(data_ballotaje_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_datos_partido(datos,partido):\n",
    "    Encuesta_col = partido + '_Encuestas'\n",
    "    fecha = ['dia', 'mes']\n",
    "    fuente = 'Fuente'\n",
    "    datos = datos[datos[partido]!=0]\n",
    "    x = datos[fecha+[partido]+[fuente]]\n",
    "    y = datos[[Encuesta_col]]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar(x,y,model,stdscaler,partido):\n",
    "    plt.figure(figsize=(15,6))\n",
    "    x_scaled = stdscaler.transform(x)\n",
    "    predicted = model.predict(x_scaled)\n",
    "    \n",
    "    xlen = np.arange(len(x))\n",
    "    plt.scatter(xlen, predicted,  label=\"Predicho\",color=\"purple\",s=5)\n",
    "    plt.scatter(xlen, y,label=\"Esperado\",color='green',s=10)\n",
    "    plt.title(partido)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_nro_partidos(datos,x_cols,y_cols,stdscaler,model):\n",
    "    nro_partidos=5\n",
    "    fig, ax = plt.subplots(nro_partidos,1,figsize=(12,5*nro_partidos))\n",
    "    x = datos.loc[:,x_cols]\n",
    "    y = datos.loc[:,y_cols]\n",
    "    x_scaled = stdscaler.transform(x)\n",
    "    predicted = model.predict(x_scaled)\n",
    "    \n",
    "    xlen = np.arange(len(x))\n",
    "    for i,a in enumerate(ax.flatten()):\n",
    "        a.scatter(xlen, predicted[:,i],  label=\"Predicho\",color=\"purple\",s=5)\n",
    "        a.scatter(xlen, y.iloc[:,i],label=\"Esperado\",color='green',s=10)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_arquitectura(in_dim,out_dim,learning_rate):\n",
    "    metrica = RootMeanSquaredError()\n",
    "    perdida = MeanSquaredError()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=in_dim,input_dim=in_dim,activation='softplus'))\n",
    "    model.add(Dense(units=(in_dim+out_dim)//2,activation='softplus'))\n",
    "    model.add(Dense(units=out_dim, activation='softplus')) \n",
    "    model.compile(loss=perdida, \n",
    "                optimizer=SGD(learning_rate=learning_rate,\n",
    "                              momentum=0.8), \n",
    "                metrics=[metrica]) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar(datos, split_training,partido):\n",
    "    #X_train, X_test, y_train, y_test = spliteo_data(datos, split_training)\n",
    "    ########## PROBANDO CON UN SOLO PARTIDO   ###############\n",
    "    #x,y = seleccionar_datos_partido(datos,partido)\n",
    "    learning_rate = 0.0005\n",
    "    ciclos = 300\n",
    "    X_train, X_test, y_train, y_test,x_cols,y_cols= spliteo_data(datos, split_training)\n",
    "    \n",
    "    x_train_scaled, x_test_scaled,stdscaler = preparar_datos_entrenamiento(X_train, X_test)\n",
    "\n",
    "    in_dim=X_train.shape[-1]\n",
    "    out_dim=y_train.shape[1]\n",
    "    \n",
    "    \n",
    "    model = modelo_arquitectura(in_dim, out_dim,learning_rate)\n",
    "\n",
    "    model.fit(x_train_scaled,y_train, epochs=ciclos, verbose=1,batch_size=16)\n",
    "    \n",
    "\n",
    "    #graficar(x,y,model,stdscaler,partido)\n",
    "    #graficar_nro_partidos(datos,x_cols,y_cols,stdscaler,model)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos modelo definitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "ciclos = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seleccionar_datos(datos):\n",
    "    cols = datos.columns.to_list()\n",
    "    idx = cols.index('Fuente')\n",
    "    x_cols = cols[:idx+1]+cols[-2:]\n",
    "    y_cols = cols[idx+2:-2]\n",
    "\n",
    "    x = datos.loc[:,x_cols]\n",
    "    y = datos.loc[:,y_cols]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/modelo_primera_vuelta\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/modelo_primera_vuelta\\assets\n"
     ]
    }
   ],
   "source": [
    "x,y = seleccionar_datos(data_encuestas_poly)\n",
    "model = modelo_arquitectura(8, 5,learning_rate)\n",
    "std_scaler = StandardScaler()\n",
    "x_scaled = std_scaler.fit_transform(x)\n",
    "model.fit(x_scaled,y, epochs=ciclos, verbose=0,batch_size=16)\n",
    "model.save('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/modelo_primera_vuelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/modelo_ballotaje\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/modelo_ballotaje\\assets\n"
     ]
    }
   ],
   "source": [
    "x,y = seleccionar_datos(data_ballotaje_poly)\n",
    "model = modelo_arquitectura(5, 2,learning_rate)\n",
    "std_scaler = StandardScaler()\n",
    "x_scaled = std_scaler.fit_transform(x)\n",
    "model.fit(x_scaled,y, epochs=ciclos, verbose=0,batch_size=16)\n",
    "model.save('C:/Users/54911/OneDrive/Escritorio/Data Science/Elecciones + IA/modeling/modelo_ballotaje')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
